input {
    file {
        path => ["/home/admin/Documents/CrownSeal/*/local1/warning.log"]
        start_position => "beginning"
        type => "fw"
        #sincedb_path => "/dev/null"
    }
}
filter {
    ## WG Web log ##
    if [type] =~ "fw"{
        grok {
            match => ["message", "%{SYSLOGTIMESTAMP:syslog_timestamp} %{HOSTNAME:devices} %{SYSLOGPROG:syslog_prog}: msg_id=\".*\" %{DATA:action} .* %{IPV4:dstip} %{IPV4:scrip} %{INT:srcport} %{INT:dstport}"]
        }
        date {
            match => [ "syslog_timestamp", "MMM  d HH:mm:ss", "MMM dd HH:mm:ss" ]
            #locale => "en"
            target => "received_at"
        }
        mutate {
            # remove_tag => [ "_grokparsefailure" ]
            add_field => { "event_type" => "fw" }
            #replace => [ "received_at", "%{@timestamp}" ]
        }
        geoip {
            source => "dstip"
            target => "geoip"
            database => "/etc/logstash/GeoLiteCity.dat"
            add_field => [ "[geoip][coordinates]", "%{[geoip][longitude]}" ]
            add_field => [ "[geoip][coordinates]", "%{[geoip][latitude]}"  ]
        }
        mutate {
            convert => [ "[geoip][coordinates]", "float"]
        }
    }

}

output {
    
    if !("_grokparsefailure" in [tags]) {
        #stdout { codec => rubydebug }
	elasticsearch {
        	hosts => ["192.168.10.127:9200"]
        	codec => "plain"
        	workers => 1
        	index => "logstash-%{+YYYY.MM.dd}"
        	manage_template => true
        	template_name => "logstash"
        	template_overwrite => false
        	flush_size => 500
        	idle_flush_time => 1

    	}	
    }
}
